{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3GxyWPtSyHlmJvB9Mogt+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinz1098/Discord_PudgyPenguins/blob/main/Step_1%3A2_Extracted_Announcement_with_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMRTq7KywHb6",
        "outputId": "0db03648-9606-403f-a609-364b2b72a136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def retrieve_messages_with_user(channel_id):\n",
        "    headers = {\n",
        "        'Authorization': 'MTE2NTk1NzY5MzcwMjQxODQ0Mw.GOmqj0.l9llP1irQfGlhpOWXvtqVyuBRivPwgosxAhqBA'  # Replace with your bot token\n",
        "    }\n",
        "    url = f'https://discord.com/api/v9/channels/{channel_id}/messages'\n",
        "    params = {\n",
        "        'limit': 100  # Number of messages per request, adjust as needed\n",
        "    }\n",
        "    all_messages = []\n",
        "\n",
        "    while True:\n",
        "        r = requests.get(url, headers=headers, params=params)\n",
        "        if r.status_code == 200:\n",
        "            json_data = r.json()\n",
        "            if not json_data:\n",
        "                break  # Break the loop if no more messages\n",
        "            all_messages.extend(json_data)\n",
        "            params['before'] = json_data[-1]['id']  # Set the 'before' parameter for pagination\n",
        "        else:\n",
        "            print(f\"Failed to retrieve messages. Status code: {r.status_code}\")\n",
        "            return\n",
        "\n",
        "    messages_data = []\n",
        "    for message in all_messages:\n",
        "        content = message['content']\n",
        "        timestamp = message['timestamp']  # Get the timestamp of the message\n",
        "        user_id = message['author']['id'] if 'author' in message else None  # Get user ID\n",
        "        messages_data.append({'Timestamp': timestamp, 'Content': content, 'User_ID': user_id})\n",
        "\n",
        "    # Convert data to DataFrame\n",
        "    df = pd.DataFrame(messages_data)\n",
        "\n",
        "    # Export to Excel\n",
        "    file_name = 'discord_messages_announcements_with_users.xlsx'  # Change the file name if needed\n",
        "    df.to_excel(file_name, index=False)\n",
        "    print(f\"Messages successfully saved to {file_name}\")\n",
        "\n",
        "retrieve_messages_with_user('865677053567565854')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B3BOCOGwQ8U",
        "outputId": "10c54e44-305c-4614-f86d-732aa7ac90bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages successfully saved to discord_messages_announcements_with_users.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL2aS9Hk95_b",
        "outputId": "fe5430af-77ed-4bdc-82a2-7016373ed8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Assuming you have already run the retrieve_messages_with_user function\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel('discord_messages_announcements_with_users.xlsx')\n",
        "\n",
        "# Function to get summary using OpenAI GPT-3.5-turbo\n",
        "def get_summary(content):\n",
        "    prompt = f\"Provide a phrase of not more than 10 words to capture the latent meaning in the following terms: '''{content}''' discussed about pudgy penguins, an NFT community channel in Discord.\"\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return completion['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Create a new column 'Summary' and generate summaries\n",
        "df['Summary'] = df['Content'].apply(get_summary)\n",
        "\n",
        "# Display the DataFrame with the added 'Summary' column\n",
        "print(df[['Content', 'Summary']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO7NF6VWyt4J",
        "outputId": "5bb69a60-d40e-4a7d-d496-d6b009b2040a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Content  \\\n",
            "0    # NFT Paris <a:Peng_croissant:9674448559219958...   \n",
            "1    **Pudgy Toys Chapter 2**\\nAs you guys know, ou...   \n",
            "2    The beginning to a new era for Web3. Pudgy Pen...   \n",
            "3    # Pudgy Penguins x NounsDAO Collectible\\nThe l...   \n",
            "4    10 Billion views on our GIFs and Stickers. Ano...   \n",
            "..                                                 ...   \n",
            "304   **Sneak Peak** at some Pudgy Penguins! @everyone   \n",
            "305  **PENGUIN DROPPPPP!** 🐧❄️\\n@everyone \\n\\nThis ...   \n",
            "306  **Hey @everyone**\\n\\nJust woke up, and I’m exc...   \n",
            "307       A look at some early penquins… ❄️🐧 @everyone   \n",
            "308  **Welcome everyone,**\\n\\nYou guys are coming i...   \n",
            "\n",
            "                                               Summary  \n",
            "0    Join us in Paris for an unforgettable night wi...  \n",
            "1    Unleashing Chapter 2: Inviting Penguin Submiss...  \n",
            "2      \"Pudgy Penguins: The NFT face of the Web3 era!\"  \n",
            "3    Limited edition Pudgy Penguins NFT collaborati...  \n",
            "4    \"Pudgy Penguins NFT community reaches 10 billi...  \n",
            "..                                                 ...  \n",
            "304  Glimpse pudgy penguins, the NFT community chan...  \n",
            "305  \"Embrace the cold and join the Pudgy Penguins ...  \n",
            "306  Excitement and anticipation for building the h...  \n",
            "307  Chubby penguins waddle in icy NFT Discord chan...  \n",
            "308  Engaging community with fast-paced interaction...  \n",
            "\n",
            "[309 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame with summaries to a new Excel file\n",
        "output_excel_file = 'discord_messages_with_AI_summaries.xlsx'\n",
        "df.to_excel(output_excel_file, index=False)"
      ],
      "metadata": {
        "id": "rbRiSgFH91Cm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}